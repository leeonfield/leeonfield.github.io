<!DOCTYPE html>
<html lang="en">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="description" content="Node.js 实现简单小说爬虫"/>




  <meta name="keywords" content="node,爬虫,小说," />




  <link rel="alternate" href="/rss2.xml" title="Leeon Notes">




  <link rel="shortcut icon" type="image/x-icon" href="/image/favicon.ico?v=2.4.x" />



<link rel="canonical" href="http://lijundong.com/novel-crawler-by-Nodejs/"/>


<meta name="description" content="最近因为剧荒，老大追了爱奇艺的一部网剧，由丁墨的同名小说《美人为馅》改编，目前已经放出两季，虽然整部剧槽点满满，但是老大看得不亦乐乎，并且在看完第二季之后跟我要小说资源，直接要奔原著去看结局……随手搜了下，都是在线资源，下载的话需要登录，注册登录好麻烦，写个爬虫玩玩也好，于是动手用 node 写了一个，这里做下笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="Node.js 实现简单小说爬虫">
<meta property="og:url" content="http://lijundong.com/novel-crawler-by-Nodejs/index.html">
<meta property="og:site_name" content="Leeon Notes">
<meta property="og:description" content="最近因为剧荒，老大追了爱奇艺的一部网剧，由丁墨的同名小说《美人为馅》改编，目前已经放出两季，虽然整部剧槽点满满，但是老大看得不亦乐乎，并且在看完第二季之后跟我要小说资源，直接要奔原著去看结局……随手搜了下，都是在线资源，下载的话需要登录，注册登录好麻烦，写个爬虫玩玩也好，于是动手用 node 写了一个，这里做下笔记">
<meta property="og:image" content="http://source.lijundong.com/public/16-11-18/1946587.jpg">
<meta property="og:image" content="http://source.lijundong.com/public/16-11-18/97144351.jpg">
<meta property="og:updated_time" content="2017-02-12T07:45:02.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Node.js 实现简单小说爬虫">
<meta name="twitter:description" content="最近因为剧荒，老大追了爱奇艺的一部网剧，由丁墨的同名小说《美人为馅》改编，目前已经放出两季，虽然整部剧槽点满满，但是老大看得不亦乐乎，并且在看完第二季之后跟我要小说资源，直接要奔原著去看结局……随手搜了下，都是在线资源，下载的话需要登录，注册登录好麻烦，写个爬虫玩玩也好，于是动手用 node 写了一个，这里做下笔记">
<meta name="twitter:image" content="http://source.lijundong.com/public/16-11-18/1946587.jpg">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.4.x" />



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />





<script>
  var CONFIG = {
    search: true,
    searchPath: "/search.xml",
    fancybox: true,
    toc: true,
  }
</script>




  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?c6907c4f3552baba34e8ee2c5980996d";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




    <title> Node.js 实现简单小说爬虫 · Leeon Notes </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Leeon Notes</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            Home
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            Archives
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            Tags
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            About
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Leeon Notes</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              Home
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              Archives
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              Tags
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              About
            
          </a>
        </li>
      
      
        <li class="menu-search">
          <form>
            <i class="iconfont icon-search" id="open-search"></i>
            <input type="text" class="search-input" id="search-input" />
            <i class="iconfont icon-close" id="close-search"></i>
          </form>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Node.js 实现简单小说爬虫
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          Nov 17, 2016
        </span>
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">Contents</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#工作流程"><span class="toc-text">工作流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#获取-URLs"><span class="toc-text">获取 URLs</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#获取数据"><span class="toc-text">获取数据</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#获取源码"><span class="toc-text">获取源码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解析源码，获取小说"><span class="toc-text">解析源码，获取小说</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#保存小说"><span class="toc-text">保存小说</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Markdown-转-PDF"><span class="toc-text">Markdown 转 PDF</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Chrome-打印"><span class="toc-text">Chrome 打印</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#pandoc-转换"><span class="toc-text">pandoc 转换</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#关于python、node、爬虫"><span class="toc-text">关于python、node、爬虫</span></a></li></ol>
    </div>
  </div>


    <div class="post-content">
      
        <p>最近因为剧荒，老大追了爱奇艺的一部网剧，由丁墨的同名小说《美人为馅》改编，目前已经放出两季，虽然整部剧槽点满满，但是老大看得不亦乐乎，并且在看完第二季之后跟我要小说资源，直接要奔原著去看结局……<br>随手搜了下，都是在线资源，下载的话需要登录，注册登录好麻烦，写个爬虫玩玩也好，于是动手用 node 写了一个，这里做下笔记<br><a id="more"></a></p>
<h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><ul>
<li>获取 URLs 列表(请求资源 <code>request</code> 模块)</li>
<li>根据 URLs 列表获取相关页面源码(可能遇到页面编码问题，<code>iconv-lite</code> 模块)</li>
<li>源码解析，获取小说信息( <code>cheerio</code> 模块)</li>
<li>保存小说信息到 Markdown 文件，并且加适当修饰以及章节信息(写文件 <code>fs</code>、同步请求资源 <code>sync-request</code> 模块)</li>
<li>Markdown 转 PDF (使用 Pandoc 或者 Chrome 的打印功能)</li>
</ul>
<h3 id="获取-URLs"><a href="#获取-URLs" class="headerlink" title="获取 URLs"></a>获取 URLs</h3><p>根据小说的导航页，获取小说所有章节的 URL，并且以 JSON 数组的方式存储。</p>
<ul>
<li>首选通过 <code>http.get()</code> 方法获取页面源码</li>
<li>获取到源码，打印发现中文乱码，查看发现 <code>charset = &#39;gbk&#39;</code>，需要进行转码</li>
<li>使用 <code>iconv-lite</code> 模块进行转码，中文显示正常后开始解析源码，获取需要的 URL，为了更方便地解析，需要引进 <code>cheerio</code> 模块，<code>cheerio</code> 可以理解为运行在后台的 jQuery，用法与 jQuery 也十分相似，熟悉 jQuery 的同学可以很快的上手</li>
<li>将源码加载进 <code>cheerio</code>，分析了源码后得知所有章节信息都存于被 <code>div</code> 包裹的 <code>a</code> 标签中，通过 <code>cheerio</code> 取出符合条件的 <code>a</code> 标签组，进行遍历，获取章节的 title 和 URL，保存为对象，存进数组，(<strong>因为链接中存储的  URL 不完整，所以存储时需要补齐</strong>)</li>
<li>将对象数组序列化，写进 <code>list.json</code> 文件</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> http = <span class="built_in">require</span>(<span class="string">"http"</span>)</span><br><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">"fs"</span>)</span><br><span class="line"><span class="keyword">var</span> cheerio = <span class="built_in">require</span>(<span class="string">"cheerio"</span>)</span><br><span class="line"><span class="keyword">var</span> iconv = <span class="built_in">require</span>(<span class="string">"iconv-lite"</span>)</span><br><span class="line"><span class="keyword">var</span> url = <span class="string">'http://www.17fa.com/files/article/html/90/90747/index.html'</span></span><br><span class="line">http.get(url, <span class="function"><span class="keyword">function</span>(<span class="params">res</span>) </span>&#123;  <span class="comment">//资源请求</span></span><br><span class="line">    <span class="keyword">var</span> chunks = []</span><br><span class="line">    res.on(<span class="string">'data'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">chunk</span>) </span>&#123;</span><br><span class="line">        chunks.push(chunk)</span><br><span class="line">    &#125;)</span><br><span class="line">    res.on(<span class="string">'end'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> html = iconv.decode(Buffer.concat(chunks), <span class="string">'gb2312'</span>) <span class="comment">//转码操作</span></span><br><span class="line">        <span class="keyword">var</span> $ = cheerio.load(html, &#123;</span><br><span class="line">            decodeEntities: <span class="literal">false</span></span><br><span class="line">        &#125;)</span><br><span class="line">        <span class="keyword">var</span> content = $(<span class="string">"tbody"</span>)</span><br><span class="line">        <span class="keyword">var</span> links = []</span><br><span class="line">        $(<span class="string">'div'</span>).children(<span class="string">'a'</span>).each(<span class="function"><span class="keyword">function</span>(<span class="params">i, elem</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">var</span> link = <span class="keyword">new</span> <span class="built_in">Object</span>()</span><br><span class="line">            link.title = $(<span class="keyword">this</span>).text()</span><br><span class="line">            link.link = <span class="string">'http://www.17fa.com/files/article/html/90/90747/'</span> + $(<span class="keyword">this</span>).attr(<span class="string">'href'</span>) <span class="comment">//补齐 URL 信息</span></span><br><span class="line">            <span class="keyword">if</span> (i &gt; <span class="number">5</span>) &#123;</span><br><span class="line">                links.push(link)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">        fs.writeFile(<span class="string">"list.json"</span>, <span class="built_in">JSON</span>.stringify(links), <span class="function"><span class="keyword">function</span>(<span class="params">err</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (!err) &#123;</span><br><span class="line">                <span class="built_in">console</span>.log(<span class="string">"写文件成功"</span>)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;).on(<span class="string">'error'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">"网页访问出错"</span>)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>获取的列表示例</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">    <span class="attr">"title"</span>: <span class="string">"3 法医司白"</span>,</span><br><span class="line">    <span class="attr">"link"</span>: <span class="string">"http://www.17fa.com/files/article/html/90/90747/16548771.html"</span></span><br><span class="line">&#125;, &#123;</span><br><span class="line">    <span class="attr">"title"</span>: <span class="string">"4 第1个梦 "</span>,</span><br><span class="line">    <span class="attr">"link"</span>: <span class="string">"http://www.17fa.com/files/article/html/90/90747/16548772.html"</span></span><br><span class="line">&#125;, &#123;</span><br><span class="line">    <span class="attr">"title"</span>: <span class="string">"5 刑警韩沉 "</span>,</span><br><span class="line">    <span class="attr">"link"</span>: <span class="string">"http://www.17fa.com/files/article/html/90/90747/16548773.html"</span></span><br><span class="line">&#125;, &#123;</span><br><span class="line">    <span class="attr">"title"</span>: <span class="string">"6 最初之战"</span>,</span><br><span class="line">    <span class="attr">"link"</span>: <span class="string">"http://www.17fa.com/files/article/html/90/90747/16548774.html "</span></span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure>
<h3 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h3><p>有了 URLs 列表，接下来的工作就很机械了，遍历 URLs 列表请求资源，获取源码，解析源码，获取小说，写文件，<strong>但是</strong>，因为最终将所有的章节保存入一个文件，要保证章节的顺序，因此写文件需要 <strong>同步操作</strong>，实际上，我在编码的时候所有的操作都改成了同步方式</p>
<h4 id="获取源码"><a href="#获取源码" class="headerlink" title="获取源码"></a>获取源码</h4><p>通过解析读取的 <code>list.json</code> 文件，获取到 URLs 列表，遍历列表获取资源，因为需要确保章节的顺序，所以这里引进 <code>sync-request</code> 模块进行同步 request 请求资源，请求资源后照例转码<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> http = <span class="built_in">require</span>(<span class="string">"http"</span>)</span><br><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">"fs"</span>)</span><br><span class="line"><span class="keyword">var</span> cheerio = <span class="built_in">require</span>(<span class="string">"cheerio"</span>)</span><br><span class="line"><span class="keyword">var</span> iconv = <span class="built_in">require</span>(<span class="string">"iconv-lite"</span>)</span><br><span class="line"><span class="keyword">var</span> request = <span class="built_in">require</span>(<span class="string">'sync-request'</span>)</span><br><span class="line"><span class="keyword">var</span> urlList = <span class="built_in">JSON</span>.parse(fs.readFileSync(<span class="string">'list.json'</span>, <span class="string">'utf8'</span>))</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getContent</span>(<span class="params">chapter</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> res = request(<span class="string">'GET'</span>,chapter.link)</span><br><span class="line">    <span class="keyword">var</span> html = iconv.decode(res.body, <span class="string">'gb2312'</span>) <span class="comment">//获取源码</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; urlList.length; i++) &#123;</span><br><span class="line">    getContent(urlList[i])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="解析源码，获取小说"><a href="#解析源码，获取小说" class="headerlink" title="解析源码，获取小说"></a>解析源码，获取小说</h4><p>还是通过 <code>cheerio</code> 模块获取小说内容，避免影响观感，写操作之前去除内容中的的 html 标签<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getContent</span>(<span class="params">chapter</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> res = request(<span class="string">'GET'</span>,chapter.link)</span><br><span class="line">    <span class="keyword">var</span> html = iconv.decode(res.body, <span class="string">'gb2312'</span>)</span><br><span class="line">    <span class="keyword">var</span> $ = cheerio.load(html, &#123;</span><br><span class="line">        decodeEntities: <span class="literal">false</span></span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="keyword">var</span> content = ($(<span class="string">"div#r1c"</span>).text()).replace(<span class="regexp">/\&amp;nbsp;/g</span>, <span class="string">''</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="保存小说"><a href="#保存小说" class="headerlink" title="保存小说"></a>保存小说</h4><p>写操作也需要同步操作，因此使用了同步写函数 <code>fs.writeFileSync()</code> 和 同步添加函数 <code>fs.appendFileSync()</code>，第一次写使用写函数，之后的内容都是进行 append 操作，<strong>为了改善阅读体验，每个章节前添加标题</strong><br><strong>也可以在内容前添加 拍 [TOC]，作为导航链接</strong></p>
<p><img src="http://source.lijundong.com/public/16-11-18/1946587.jpg" style="border-radius: 0.5rem;border:0;"></p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> http = <span class="built_in">require</span>(<span class="string">"http"</span>)</span><br><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">"fs"</span>)</span><br><span class="line"><span class="keyword">var</span> cheerio = <span class="built_in">require</span>(<span class="string">"cheerio"</span>)</span><br><span class="line"><span class="keyword">var</span> iconv = <span class="built_in">require</span>(<span class="string">"iconv-lite"</span>)</span><br><span class="line"><span class="keyword">var</span> path = <span class="built_in">require</span>(<span class="string">'path'</span>)</span><br><span class="line"><span class="keyword">var</span> urlList = <span class="built_in">JSON</span>.parse(fs.readFileSync(<span class="string">'list.json'</span>, <span class="string">'utf8'</span>))</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getContent</span>(<span class="params">chapter</span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(chapter.link)</span><br><span class="line">    http.get(chapter.link, <span class="function"><span class="keyword">function</span>(<span class="params">res</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> chunks = []</span><br><span class="line">        res.on(<span class="string">'data'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">chunk</span>) </span>&#123;</span><br><span class="line">            chunks.push(chunk)</span><br><span class="line">        &#125;)</span><br><span class="line">        res.on(<span class="string">'end'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">            <span class="keyword">var</span> html = iconv.decode(Buffer.concat(chunks), <span class="string">'gb2312'</span>)</span><br><span class="line">            <span class="keyword">var</span> $ = cheerio.load(html, &#123;</span><br><span class="line">                decodeEntities: <span class="literal">false</span></span><br><span class="line">            &#125;)</span><br><span class="line">            <span class="keyword">var</span> content = ($(<span class="string">"div#r1c"</span>).text()).replace(<span class="regexp">/\&amp;nbsp;/g</span>, <span class="string">''</span>)</span><br><span class="line">            <span class="keyword">if</span> (fs.existsSync(<span class="string">'美人为馅.md'</span>)) &#123;</span><br><span class="line">                fs.appendFileSync(<span class="string">'美人为馅.md'</span>, <span class="string">'### '</span> + chapter.title)</span><br><span class="line">                fs.appendFileSync(<span class="string">'美人为馅.md'</span>, content)</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                fs.writeFileSync(<span class="string">'美人为馅.md'</span>, <span class="string">'### '</span> + chapter.title)</span><br><span class="line">                fs.appendFileSync(<span class="string">'美人为馅.md'</span>, content)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;).on(<span class="string">'error'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">"爬取"</span> + chapter.link + <span class="string">"链接出错！"</span>)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; urlList.length; i++) &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(urlList[i])</span><br><span class="line">    getContent(urlList[i])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Markdown-转-PDF"><a href="#Markdown-转-PDF" class="headerlink" title="Markdown 转 PDF"></a>Markdown 转 PDF</h3><p>我将小说保存在 Markdown 文件中，为了提升阅读体验，可以将 Markdown 文件转换成 PDF 文件，目前我较为喜欢的两种方式，通过 Chrome 的打印功能 以及 pandoc 转换</p>
<h4 id="Chrome-打印"><a href="#Chrome-打印" class="headerlink" title="Chrome 打印"></a>Chrome 打印</h4><p>SublimeText 有个插件 <code>markdown preview</code> ，可通过 <code>Alt + m</code> 快捷键在 Chrome 中预览 Markdown，在 Chrome 页面中右键，选择打印，调整好参数后，选择另存为 PDF，简单，粗暴，深得我心<br><strong>打印效果：</strong><br><img src="http://source.lijundong.com/public/16-11-18/97144351.jpg" alt=""></p>
<h4 id="pandoc-转换"><a href="#pandoc-转换" class="headerlink" title="pandoc 转换"></a>pandoc 转换</h4><p>pandoc 是十分强大的文件格式转换工具，可以将 Markdown 文件转换成多种格式，今晚在 windows10 下折腾了半天，始终检索不到 pdflatex，关于 pandoc，后面会专门写一篇总结。 </p>
<p>PDF 已经发给老大了，现在正在看</p>
<h3 id="关于python、node、爬虫"><a href="#关于python、node、爬虫" class="headerlink" title="关于python、node、爬虫"></a>关于python、node、爬虫</h3><p>在之前很长的一段时间里，很想用 Python，很想写爬虫，更想用 Python 写爬虫，甚至成为了心里的一块执念，随着接触的知识更全面，执念也逐渐淡去，少了很多“想”，遇事想着多去动手，实践出真知。</p>
<hr>
<p><em>talk is cheap, show me your code</em></p>

      
    </div>

    
      
      

  <div class="post-copyright">
    <p class="copyright-item">
      <span>Author: </span>
      <span>leeon</span>
    </p>
    <p class="copyright-item">
      <span>Origin: </span>
      <a href="http://lijundong.com">http://lijundong.com</a>
    </p>
    <p class="copyright-item">
      <span>Link: </span>
      <a href="http://lijundong.com/novel-crawler-by-Nodejs/">http://lijundong.com/novel-crawler-by-Nodejs/</a>
    </p>

    <p class="copyright-item lincese">
      
      本文采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可
    </p>
  </div>



      
      
  <div class="post-reward">
    <input type="checkbox" name="reward" id="reward" hidden />
    <label class="reward-button" for="reward">Reward</label>
    <div class="qr-code">
      
      
        <label class="qr-code-image" for="reward">
          <img class="image" src="/image/reward/wechat.png" title="wechat">
        </label>
      
      
        <label class="qr-code-image" for="reward">
          <img class="image" src="/image/reward/alipay.png" title="alipay">
        </label>
      
    </div>
  </div>

    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/node/">node</a>
            
              <a href="/tags/爬虫/">爬虫</a>
            
              <a href="/tags/小说/">小说</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/start-latex-and-configure-latext-editor-with-sublime/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">SublimeText 配置 LaTeX 编辑器</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/develop-automatic-gulp-set/">
        <span class="next-text nav-default">前端开发自动化之 Gulp</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>  
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:leeonfield@gmail.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/lijundong" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
    
      
    
    
    
      <a href="/rss2.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>



<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a>
  </span>
  
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2015 - 
    
    2017

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">leeon</span>
  </span>
</div>
      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  

  
  <script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://lijundong.com/novel-crawler-by-Nodejs/';
        this.page.identifier = 'novel-crawler-by-Nodejs/';
        this.page.title = 'Node.js 实现简单小说爬虫';
    };
    (function() {
    var d = document, s = d.createElement('script');

    s.src = '//http-www-lijundong-com.disqus.com/embed.js';

    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();  
  </script>

  




    
  





  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.4.x"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=2.4.x"></script>

    
  <script type="text/html" id="search-result">
    <article class="post">
      <header class="post-header">
        <h1 class="post-title">
          <a href="$url$" class="post-link">
            $title$
          </a>
        </h1>
      </header>
      <div class="post-content">
        $content$
        <div class="read-more">
          <a href="$url$" class="read-more-link">
            Read more..
          </a>
        </div>
      </div>
    </article>
  </script>
  <script type="text/html" id="no-search-result">
    <div class="no-result">
      <h2>No result found!</h2>
    </div>
  </script>
  <script type="text/javascript" src="/js/src/search.js?v=2.4.x"></script>

  </body>
</html>
